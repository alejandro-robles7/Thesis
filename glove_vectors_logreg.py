#Using glove vectors as input to train an Multiclass Logistic Regression, Binary Logistic Regression, or SVM
#glove vectors are generated by a pretrained spacy model (pretrained on common crawl)

from sklearn.preprocessing import StandardScaler
from pandas import read_csv
from spacy import load
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import SGDClassifier, LogisticRegression
from numpy import load
from pickle import dump

def load_data(path='files/data_cleaned.txt'):
    df = read_csv(path, header= None, names = ['Category', 'Text'], sep =' ')
    X = df['Text']
    y = df['Category']
    return X, y

def generate_embeddings(X):
    nlp = load('en_core_web_lg')
    docs = list(nlp.pipe(X))
    return [doc.vector for doc in docs]

def create_embeddings(X, path_model='en_core_web_lg'):
    nlp = load(path_model)
    sentence_embeddings = []
    for row in X:
        sentence_embeddings.append(nlp(row).vector)
    return sentence_embeddings

def split_dataset(X_input, y_input):
    return train_test_split(X_input, y_input, test_size=0.3, random_state=42)

def train_model(X_input, y_input, svm_log='log'):
    if svm_log == 'log':
        classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs')
    elif svm_log == 'log_binary':
        classifier = LogisticRegression()
    else:
        classifier = SGDClassifier(loss="hinge", penalty="l2", max_iter = 100, shuffle=True)
    classifier.fit(X_input, y_input)
    return classifier

def normalize_data(X_train, X_test):
    scaler = StandardScaler()
    scaler.fit(X_train)
    X_train_new = scaler.transform(X_train)
    X_test_new = scaler.transform(X_test)
    return X_train_new, X_test_new

def calc_accuracy(classifier, X_test, y_test):
    y_pred = classifier.predict(X_test)
    print('accuracy %s' % accuracy_score(y_pred, y_test))
    print("report linear model", classification_report(y_test, y_pred, target_names=classifier.classes_))
    return accuracy_score(y_pred, y_test)

def save_model(model, path):
    with open(path, 'wb') as file:
        dump(model, file)

def get_embeddings(path='/Users/alejandro.robles/PycharmProjects/Thesis/files/doc_embeddings.npy'):
    return load(path)

def binarize_ind(data, other_cat=None, main_cat='__label__sports', one_vs_all=False):
    main_ind = data == main_cat
    if one_vs_all:
        other_ind = ~main_ind

    elif other_cat:
        other_ind = data == other_cat

    else:
        other_ind = None

    return main_ind, other_ind

def train_pipeline(x, y, svm_log='log'):
    X_train, X_test, y_train, y_test = split_dataset(x, y)
    X_train_new, X_test_new = normalize_data(X_train, X_test)
    model = train_model(X_train_new, y_train, svm_log=svm_log)
    return calc_accuracy(model, X_test_new, y_test), model

def mask_label(labels, ind, new_label='__label__other'):
    labels[ind] = new_label
    return labels


if __name__ == '__main__':
    csv_path_cleaned = 'files/data_cleaned.txt'
    model_type = 'log_binary'
    save_model_flag = False

    X, y = load_data(csv_path_cleaned)
    sentence_embeddings = get_embeddings()

    if model_type == 'log_binary':
        sports_ind, other_ind = binarize_ind(y, one_vs_all=True)
        y = mask_label(y, other_ind)

    accuracy, model = train_pipeline(sentence_embeddings, y, svm_log=model_type)

    if save_model_flag:
        save_model(model, path='temp_model.pkl')
